import pandas as pd
import numpy as np
import pickle
import os
import glob
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.cluster import KMeans
from collections import Counter

# Import ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÄ‡∏î‡∏¥‡∏°‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡∏°‡∏µ
from clean_cosmetic_ingredients import clean_ingredients
from model_training import train_from_scratch

# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå
DATA_DIR = "data"
OUTPUT_DIR = "model_output"
os.makedirs(OUTPUT_DIR, exist_ok=True)

def load_and_combine_data(data_dir):
    """‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå CSV ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå data ‡∏°‡∏≤‡∏£‡∏ß‡∏°‡∏Å‡∏±‡∏ô"""
    all_files = glob.glob(os.path.join(data_dir, "*.csv"))
    
    # ‡∏Å‡∏£‡∏≠‡∏á‡πÄ‡∏≠‡∏≤‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô Raw Data (‡πÑ‡∏°‡πà‡πÄ‡∏≠‡∏≤‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà clean ‡πÅ‡∏•‡πâ‡∏ß)
    raw_files = [f for f in all_files if "cleaned" not in f and "report" not in f]
    
    print(f"üìÇ Found {len(raw_files)} data files: {[os.path.basename(f) for f in raw_files]}")
    
    df_list = []
    for filename in raw_files:
        try:
            temp_df = pd.read_csv(filename)
            # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå skin_type ‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏Å‡πà‡∏≤)
            if 'skin_type' not in temp_df.columns:
                temp_df['skin_type'] = np.nan
            df_list.append(temp_df)
        except Exception as e:
            print(f"‚ö†Ô∏è Error reading {filename}: {e}")
            
    if not df_list:
        raise ValueError("No CSV files found in data directory!")
        
    combined_df = pd.concat(df_list, ignore_index=True)
    print(f"‚úÖ Combined Data: {len(combined_df)} total rows")
    return combined_df

def process_skin_type_column(df):
    """‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Skin Type ‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô List ‡πÅ‡∏•‡∏∞‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Ñ‡πà‡∏≤‡∏ß‡πà‡∏≤‡∏á"""
    def clean_skin_type(x):
        if pd.isna(x) or str(x).strip() == "":
            return []
        return [s.strip().lower() for s in str(x).split(',')]
    
    return df['skin_type'].apply(clean_skin_type)

def main():
    # 1. Load & Combine Data
    df = load_and_combine_data(DATA_DIR)
    
    # 2. Clean Ingredients
    print("Cleaning ingredients...")
    # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô string ‡∏Å‡πà‡∏≠‡∏ô‡∏Å‡∏±‡∏ô error
    df['ingredients'] = df['ingredients'].astype(str)
    df['clean_ingredients'] = df['ingredients'].apply(clean_ingredients)
    
    # ‡∏•‡∏ö‡πÅ‡∏ñ‡∏ß‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏™‡πà‡∏ß‡∏ô‡∏ú‡∏™‡∏° (‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å clean)
    df = df[df['clean_ingredients'] != ""]
    
    # ==========================================
    # PART 1: Update Association Model
    # ==========================================
    print("\n--- Training Association Rules ---")
    # ‡πÉ‡∏ä‡πâ train_from_scratch ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏´‡∏°‡πà‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏£‡∏ß‡∏°
    train_from_scratch(df, cleaned_csv=os.path.join(DATA_DIR, "cosmetics_cleaned_final.csv"))
    print("Association Model Updated!")

    # ==========================================
    # PART 2: New K-Means with Skin Type Logic
    # ==========================================
    print("\n--- Training K-Means & Skin Type Mapping ---")
    
    # 2.1 Vectorize
    vectorizer = TfidfVectorizer(tokenizer=lambda x: x.split(', '), token_pattern=None)
    X = vectorizer.fit_transform(df['clean_ingredients'])
    
    # 2.2 Clustering
    K = 5 # ‡∏õ‡∏£‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Å‡∏•‡∏∏‡πà‡∏°‡πÑ‡∏î‡πâ‡∏ï‡∏≤‡∏°‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
    kmeans = KMeans(n_clusters=K, random_state=42)
    clusters = kmeans.fit_predict(X)
    df['cluster'] = clusters
    
    # 2.3 Analyze Skin Type per Cluster
    df['skin_type_list'] = process_skin_type_column(df)
    
    cluster_profile = {}
    feature_names = np.array(vectorizer.get_feature_names_out())

    for i in range(K):
        cluster_products = df[df['cluster'] == i]
        
        # ‡∏ô‡∏±‡∏ö Skin Type ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏à‡∏≤‡∏Å‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏´‡∏°‡πà)
        all_skin_types = [st for sublist in cluster_products['skin_type_list'] for st in sublist]
        
        if all_skin_types:
            skin_counts = Counter(all_skin_types)
            top_skin_types = [st for st, count in skin_counts.most_common(3)]
        else:
            top_skin_types = ["unknown"] # ‡∏Å‡∏£‡∏ì‡∏µ‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏ô‡∏µ‡πâ‡∏°‡∏≤‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏Å‡πà‡∏≤‡∏•‡πâ‡∏ß‡∏ô‡πÜ
            
        # ‡∏´‡∏≤ Key Ingredients (Centroid)
        centroid = kmeans.cluster_centers_[i]
        top_indices = centroid.argsort()[-10:][::-1]
        key_ingredients = feature_names[top_indices].tolist()
        
        cluster_profile[i] = {
            "dominant_skin_types": top_skin_types,
            "key_ingredients": key_ingredients,
            "product_count": len(cluster_products)
        }
        
        print(f"Cluster {i} ({len(cluster_products)} products):")
        print(f"  - Suitable for: {top_skin_types}")
        print(f"  - Key Ingredients: {key_ingredients[:3]}...")

    # 2.4 Save Models
    print(f"\nSaving K-Means models to {OUTPUT_DIR}...")
    with open(os.path.join(OUTPUT_DIR, "cluster_profile.pkl"), "wb") as f:
        pickle.dump(cluster_profile, f)
        
    # (Optional: ‡∏ñ‡πâ‡∏≤‡∏à‡∏∞ save vectorizer/kmeans model ‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡πá‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ)
        
    print("All Done! Ready to use.")

if __name__ == "__main__":
    main()